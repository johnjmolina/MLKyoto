Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Krogstad2005,
abstract = {The integrating factor (IF) method for numerical integration of stiff nonlinear PDEs has the disadvantage of producing large error coefficients when the linear term has large norm. We propose a generalization of the IF method, and in particular construct multistep-type methods with several orders of magnitude improved accuracy. We also consider exponential time differencing (ETD) methods, and point out connections with a particular application of the commutator-free Lie group methods. We present a new fourth order ETDRK method with improved accuracy. The methods considered are compared in several numerical examples. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Krogstad, Stein},
doi = {10.1016/j.jcp.2004.08.006},
file = {:Users/john/Documents/Mendeley Desktop/Krogstad/Journal of Computational Physics/Krogstad - 2005 - Generalized integrating factor methods for stiff PDEs.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Exponential time differencing,Integrating factor methods,Lie group methods,Stiff systems},
number = {1},
pages = {72--88},
title = {{Generalized integrating factor methods for stiff PDEs}},
volume = {203},
year = {2005}
}
@article{Hochbruck2005,
abstract = {The aim of this paper is to construct exponential Runge-Kutta methods of collocation type and to analyze their convergence properties for linear and semilinear parabolic problems. For the analysis, an abstract Banach space framework of sectorial operators and locally Lipschitz continuous nonlinearities is chosen. This framework includes interesting examples like reaction-diffusion equations. It is shown that the methods converge at least with their stage order, and that convergence of higher order (up to the classical order) occurs, if the problem has sufficient temporal and spatial smoothness. The latter, however, might require the source function to fulfil unnatural boundary conditions. Therefore, the classical order is not always obtained and an order reduction must be expected, in general. {\textcopyright} 2004 IMACS. Published by Elsevier B.V. All rights reserved.},
author = {Hochbruck, Marlis and Ostermann, Alexander},
doi = {10.1016/j.apnum.2004.08.005},
file = {:Users/john/Documents/Mendeley Desktop/Hochbruck, Ostermann/Applied Numerical Mathematics/Hochbruck, Ostermann - 2005 - Exponential Runge-Kutta methods for parabolic problems.pdf:pdf},
issn = {01689274},
journal = {Applied Numerical Mathematics},
keywords = {Convergence bounds,Exponential collocation methods,Exponential quadrature rules,Preservation of equilibria,Semilinear parabolic problems},
number = {2-4},
pages = {323--339},
title = {{Exponential Runge-Kutta methods for parabolic problems}},
volume = {53},
year = {2005}
}
@article{Perdikaris2017,
abstract = {PP, 0000-0002-2816-3229 Multi-fidelity modelling enables accurate inference of quantities of interest by synergistically combining realizations of low-cost/low-fidelity models with a small set of high-fidelity observations. This is particularly effective when the low-and high-fidelity models exhibit strong correlations, and can lead to significant computational gains over approaches that solely rely on high-fidelity models. However, in many cases of practical interest, low-fidelity models can only be well correlated to their high-fidelity counterparts for a specific range of input parameters, and potentially return wrong trends and erroneous predictions if probed outside of their validity regime. Here we put forth a probabilistic framework based on Gaussian process regression and nonlinear autoregressive schemes that is capable of learning complex nonlinear and space-dependent cross-correlations between models of variable fidelity, and can effectively safeguard against low-fidelity models that provide wrong trends. This introduces a new class of multi-fidelity information fusion algorithms that provide a fundamental extension to the existing linear autoregressive methodologies, while still maintaining the same algorithmic complexity and overall computational cost. The performance of the proposed methods is tested in several benchmark problems involving both synthetic and real multi-fidelity datasets from computational fluid dynamics simulations.},
author = {Perdikaris, P. and Raissi, M. and Damianou, A. and Lawrence, N. D. and Karniadakis, G. E.},
doi = {10.1098/rspa.2016.0751},
file = {:Users/john/Documents/Mendeley Desktop/Perdikaris et al/Proceedings of the Royal Society A Mathematical, Physical and Engineering Science/Perdikaris et al. - 2017 - Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling.pdf:pdf},
issn = {1364-5021},
journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science},
number = {2198},
pages = {20160751},
title = {{Nonlinear information fusion algorithms for data-efficient multi-fidelity modelling}},
url = {http://rspa.royalsocietypublishing.org/lookup/doi/10.1098/rspa.2016.0751},
volume = {473},
year = {2017}
}
@article{Trefethen2006,
abstract = {Many computational problems can be solved with the aid of contour integrals containing {\$}e{\^{}}z{\$} in the the integrand: examples include inverse Laplace transforms, special functions, functions of matrices and operators, parabolic PDEs, and reaction-diffusion equations. One approach to the numerical quadrature of such integrals is to apply the trapezoid rule on a Hankel contour defined by a suitable change of variables. Optimal parameters for three classes of such contours have recently been derived: (a) parabolas, (b) hyperbolas, and (c) cotangent contours, following Talbot in 1979. The convergence rates for these optimized quadrature formulas are very fast: roughly {\$}O(3{\^{}}{\{}-N{\}}){\$}, where {\$}N{\$} is the number of sample points or function evaluations. On the other hand, convergence at a rate apparently about twice as fast, {\$}O(9.28903{\^{}}{\{}-N{\}}){\$}, can be achieved by using a different approach: best supremum-norm rational approximants to {\$}e{\^{}}z{\$} for {\$}z\backslashin (-\backslashinfty,0]{\$}, following Cody, Meinardus and Varga in 1969. (All these rates are doubled in the case of self-adjoint operators or real integrands.) It is shown that the quadrature formulas can be interpreted as rational approximations and the rational approximations as quadrature formulas, and the strengths and weaknesses of the different approaches are discussed in the light of these connections. A MATLAB function is provided for computing Cody--Meinardus--Varga approximants by the method of Carath{\`{e}}odory-Fej{\`{e}}r approximation.},
author = {Trefethen, L. N. and Weideman, J. A.C. and Schmelzer, T.},
doi = {10.1007/s10543-006-0077-9},
file = {:Users/john/Documents/Mendeley Desktop/Trefethen, Weideman, Schmelzer/BIT Numerical Mathematics/Trefethen, Weideman, Schmelzer - 2006 - Talbot quadratures and rational approximations.pdf:pdf},
issn = {00063835},
journal = {BIT Numerical Mathematics},
keywords = {Carath{\'{e}}odory-Fej{\'{e}}r approximation,Hankel contour,Inverse Laplace transform,Quadrature,Rational approximation,Special functions,Talbot contour,Trapezoid rule},
number = {3},
pages = {653--670},
title = {{Talbot quadratures and rational approximations}},
volume = {46},
year = {2006}
}
@article{Hochbruck2005a,
abstract = {The aim of this paper is to analyze explicit exponential Runge--Kutta methods for the time integration of semilinear parabolic problems. The analysis is performed in an abstract Banach space framework of sectorial operators and locally Lipschitz continuous nonlinearities. We commence by giving a new and short derivation of the classical (nonstiff) order conditions for exponential Runge--Kutta methods, but the main interest of our paper lies in the stiff case. By expanding the errors of the numerical method in terms of the solution, we derive new order conditions that form the basis of our error bounds for parabolic problems. We show convergence for methods up to order four, and we analyze methods that were recently presented in the literature. These methods have classical order four, but they do not satisfy some of the new conditions. Therefore, an order reduction is expected. We present numerical experiments which show that this order reduction in fact arises in practical examples. Based on our new condi...},
author = {Hochbruck, Marlis and Ostermann, Alexander},
doi = {10.1137/040611434},
file = {:Users/john/Documents/Mendeley Desktop/Hochbruck, Ostermann/SIAM Journal on Numerical Analysis/Hochbruck, Ostermann - 2005 - Explicit Exponential Runge--Kutta Methods for Semilinear Parabolic Problems.pdf:pdf},
issn = {0036-1429},
journal = {SIAM Journal on Numerical Analysis},
keywords = {65L06,65M12,Runge--Kutta methods,convergence,explicit high-order methods,exponential integrators,order reduction,semilinear parabolic problems,stiff order conditions},
month = {jan},
number = {3},
pages = {1069--1090},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Explicit Exponential Runge--Kutta Methods for Semilinear Parabolic Problems}},
url = {http://epubs.siam.org/doi/10.1137/040611434},
volume = {43},
year = {2005}
}
@article{Rothauge2016,
abstract = {The implementation of the discrete adjoint method for exponential time differencing (ETD) schemes is considered. This is important for parameter estimation problems that are constrained by stiff time-dependent PDEs when the discretized PDE system is solved using an exponential integrator. We also discuss the closely related topic of computing the action of the sensitivity matrix on a vector, which is required when performing a sensitivity analysis. The PDE system is assumed to be semi-linear and can be the result of a linearization of a nonlinear PDE, leading to exponential Rosenbrock-type methods. We discuss the computation of the derivatives of the {\$}\backslashvarphi{\$}-functions that are used by ETD schemes and find that the derivatives strongly depend on the way the {\$}\backslashvarphi{\$}-functions are evaluated numerically. A general adjoint exponential integration method, required when computing the gradients, is developed and its implementation is illustrated by applying it to the Krogstad scheme. The applicability of the methods developed here to pattern formation problems is demonstrated using the Swift-Hohenberg model.},
archivePrefix = {arXiv},
arxivId = {1610.02596},
author = {Rothauge, Kai and Haber, Eldad and Ascher, Uri},
eprint = {1610.02596},
file = {:Users/john/Documents/Mendeley Desktop/Rothauge, Haber, Ascher/Unknown/Rothauge, Haber, Ascher - 2016 - The Discrete Adjoint Method for Exponential Integration.pdf:pdf},
keywords = {adjoint,ams subject classifications,exponential integration,gradient-based optimization,high-order time-stepping methods,inverse problems,method,numerical analysis,optimization,parameter estimation,partial differential equations,pat-,rosenbrock method,semi-linear pde,sensitivity analysis,swift-hohenberg equation,tern formation},
pages = {1--28},
title = {{The Discrete Adjoint Method for Exponential Integration}},
url = {http://arxiv.org/abs/1610.02596},
year = {2016}
}
@article{Schmelzer2007,
abstract = {Among the fastest methods for solving stiff PDE are exponential integrators, which require the ??????? ?? ? ? ?? ! {\#}"{\%}{\$}!?'{\&}( ? ? ? ? evaluation of , where is a negative semidefinite matrix and is the exponential function or one of the related “ functions” such as . Building on previous work by Trefethen and Gutknecht, Minchev, and Lu, we propose two methods for the fast evaluation of that are especially useful when shifted systems can be solved efficiently, e.g. by a sparse direct solver. The first method is based on best rational approximations to on the negative real axis computed via the Carath{\'{e}}odory-Fej{\'{e}}r procedure. Rather than using optimal poles we approximate the functions in a set of common poles, which speeds up typical computations by a factor of ?)?101 32 ?546 87 to . The second method is an application of the trapezoid rule on a Talbot-type contour.},
author = {Schmelzer, Thomas and Trefethen, Lloyd N.},
file = {:Users/john/Documents/Mendeley Desktop/Schmelzer, Trefethen/Electronic Transactions on Numerical Analysis/Schmelzer, Trefethen - 2007 - Evaluating Matrix Functions for Exponential Integrators Via Caratheodory-Fejer Approximation and Contour I.pdf:pdf},
isbn = {1068-9613},
issn = {10689613},
journal = {Electronic Transactions on Numerical Analysis},
keywords = {Exponential integrators,Hankel contour,Matrix exponential,Numerical quadrature,Rational uniform approximation,Stiff semilinear parabolic PDEs},
pages = {1--18},
title = {{Evaluating Matrix Functions for Exponential Integrators Via Caratheodory-Fejer Approximation and Contour Integrals}},
volume = {29},
year = {2007}
}
@article{Cox2002,
abstract = {We develop a class of numerical methods for stiff systems, based on the method of exponential time differencing. We describe schemes with second- and higher-order accuracy, introduce new Runge-Kutta versions of these schemes, and extend the method to show how it may be applied to systems whose linear part is nondiagonal. We test the method against other common schemes, including integrating factor and linearly implicit methods, and show how it is more accurate in a number of applications. We apply the method to both dissipative and dispersive partial differential equations, after illustrating its behavior using forced ordinary differential equations with stiff linear parts. {\textcopyright} 2002 Elsevier Science (USA).},
author = {Cox, S. M. and Matthews, P. C.},
doi = {10.1006/jcph.2002.6995},
file = {:Users/john/Documents/Mendeley Desktop/Cox, Matthews/Journal of Computational Physics/Cox, Matthews - 2002 - Exponential time differencing for stiff systems.pdf:pdf},
isbn = {0021-9991},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {Exponential time differencing,Integrating factor methods,Stiff systems},
number = {2},
pages = {430--455},
title = {{Exponential time differencing for stiff systems}},
volume = {176},
year = {2002}
}
@article{Raissi2017,
abstract = {We introduce the concept of numerical Gaussian processes, which we define as Gaussian processes with covariance functions resulting from temporal discretization of time-dependent partial differential equations. Numerical Gaussian processes, by construction, are designed to deal with cases where: (1) all we observe are noisy data on black-box initial conditions, and (2) we are interested in quantifying the uncertainty associated with such noisy data in our solutions to time-dependent partial differential equations. Our method circumvents the need for spatial discretization of the differential operators by proper placement of Gaussian process priors. This is an attempt to construct structured and data-efficient learning machines, which are explicitly informed by the underlying physics that possibly generated the observed data. The effectiveness of the proposed approach is demonstrated through several benchmark problems involving linear and nonlinear time-dependent operators. In all examples, we are able to recover accurate approximations of the latent solutions, and consistently propagate uncertainty, even in cases involving very long time integration.},
archivePrefix = {arXiv},
arxivId = {1703.10230},
author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
doi = {10.1137/17M1120762},
eprint = {1703.10230},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Perdikaris, Karniadakis/Unknown/Raissi, Perdikaris, Karniadakis - 2017 - Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations.pdf:pdf},
issn = {10957197},
keywords = {bayesian modeling,linear multi-step methods,name,preprint submitted to journal,probabilistic machine learning,runge-kutta methods,uncertainty quantification},
pages = {1--50},
title = {{Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations}},
url = {http://arxiv.org/abs/1703.10230},
year = {2017}
}
@book{Sivia2006,
address = {Oxford},
author = {Sivia, D. S and Skilling, J.},
edition = {2nd},
publisher = {Oxford University Press},
title = {{Data Analysis: A Bayesian Tutorial}},
year = {2006}
}
@article{Raissi2017a,
abstract = {For more than two centuries, solutions of differential equations have been obtained either analytically or numerically based on typically well-behaved forcing and boundary conditions for well-posed problems. We are changing this paradigm in a fundamental way by establishing an interface between probabilistic machine learning and differential equations. We develop data-driven algorithms for general linear equations using Gaussian process priors tailored to the corresponding integro-differential operators. The only observables are scarce noisy multi-fidelity data for the forcing and solution that are not required to reside on the domain boundary. The resulting predictive posterior distributions quantify uncertainty and naturally lead to adaptive solution refinement via active learning. This general framework circumvents the tyranny of numerical discretization as well as the consistency and stability issues of time-integration, and is scalable to high-dimensions.},
author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
doi = {10.1016/j.jcp.2017.01.060},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Perdikaris, Karniadakis/Journal of Computational Physics/Raissi, Perdikaris, Karniadakis - 2017 - Inferring solutions of differential equations using noisy multi-fidelity data.pdf:pdf},
issn = {10902716},
journal = {Journal of Computational Physics},
keywords = {Integro-differential equations,Machine learning,Multi-fidelity modeling,Uncertainty quantification},
pages = {736--746},
publisher = {Elsevier Inc.},
title = {{Inferring solutions of differential equations using noisy multi-fidelity data}},
url = {http://dx.doi.org/10.1016/j.jcp.2017.01.060},
volume = {335},
year = {2017}
}
@article{Bastin2013b,
archivePrefix = {arXiv},
arxivId = {arXiv:1302.5877},
author = {Hochbruck, Marlis and Ostermann, Alexander and Schweitzer, Julia},
doi = {10.1137/090750688},
eprint = {arXiv:1302.5877},
file = {:Users/john/Documents/Mendeley Desktop/Hochbruck, Ostermann, Schweitzer/SIAM J. Numer. Anal/Hochbruck, Ostermann, Schweitzer - 2009 - Exponential Rosenbrock-type methods.pdf:pdf},
isbn = {0001405101},
issn = {0022-3999},
journal = {SIAM J. Numer. Anal.},
keywords = {10,1137,120875739,35f25,35f30,93d20,93d30,ams subject classifications,backstepping,boundary conditions,doi,goursat problem,integral equation,lyapunov function,method of characteristics,nonlinear hyperbolic systems,stability},
number = {1},
pages = {786--803},
title = {{Exponential Rosenbrock-type methods}},
volume = {47},
year = {2009}
}
@article{Raissi2017b,
abstract = {This work leverages recent advances in probabilistic machine learning to discover governing equations expressed by parametric linear operators. Such equations involve, but are not limited to, ordinary and partial differential, integro-differential, and fractional order operators. Here, Gaussian process priors are modified according to the particular form of such operators and are employed to infer parameters of the linear equations from scarce and possibly noisy observations. Such observations may come from experiments or ''black-box" computer simulations, as demonstrated in several synthetic examples and a realistic application in functional genomics.},
author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
doi = {10.1016/j.jcp.2017.07.050},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Perdikaris, Karniadakis/Journal of Computational Physics/Raissi, Perdikaris, Karniadakis - 2017 - Machine learning of linear differential equations using Gaussian processes.pdf:pdf},
issn = {10902716},
journal = {Journal of Computational Physics},
keywords = {Fractional differential equations,Functional genomics,Inverse problems,Probabilistic machine learning,Uncertainty quantification},
pages = {683--693},
publisher = {Elsevier Inc.},
title = {{Machine learning of linear differential equations using Gaussian processes}},
url = {http://dx.doi.org/10.1016/j.jcp.2017.07.050},
volume = {348},
year = {2017}
}
@book{Hochbruck2010,
abstract = {We give an introduction to exponential integrators, starting with a motivation for their use. A format for describing exponential integrators as an extension of general linear schemes (including RK-schemes and multistep-schemes), and order conditions in this setup are developed. Stiff order conditions are relevant for parabolic problems and are also described. A Matlab package has been developed to ease the implementation and testing of most known exponential integrators, we describe this package and end with some numerical examples using it.},
author = {Hochbruck, Marlis and Ostermann, Alexander},
booktitle = {Acta Numerica},
doi = {10.1017/S0962492910000048},
file = {:Users/john/Documents/Mendeley Desktop/Hochbruck, Ostermann/Acta Numerica/Hochbruck, Ostermann - 2010 - Exponential integrators.pdf:pdf},
isbn = {0962492910000},
issn = {09624929},
number = {May 2010},
pages = {209--286},
title = {{Exponential integrators}},
volume = {19},
year = {2010}
}
@article{Sivia1998,
abstract = {We outline the basic principles of Bayesian probability theory and illustrate its use with reflectivity data. This approach provides a unified rationale for data analysis, which both justifies many of the commonly used analysis procedures and indicates some natural extensions that enhance their potency. Thus, for example, we find that the ubiquitous least-squares apparatus of parameter estimation is easily adapted to tackle the more intriguing question of model selection. A free-form solution application is also presented, as is a discussion of the difficult but important question of optimal experimental design. {\textcopyright} 1998 Elsevier Science B.V. All rights reserved.},
author = {Sivia, D. S. and Webster, J. R.P.},
doi = {10.1016/S0921-4526(98)00259-2},
file = {:Users/john/Documents/Mendeley Desktop/Sivia, Webster/Physica B Condensed Matter/Sivia, Webster - 1998 - The Bayesian approach to reflectivity data.pdf:pdf},
issn = {09214526},
journal = {Physica B: Condensed Matter},
keywords = {Bayesian probability theory,Experimental design,Maximum entropy,Model selection},
number = {1-4},
pages = {327--337},
title = {{The Bayesian approach to reflectivity data}},
volume = {248},
year = {1998}
}
@article{Rudy2017,
abstract = {We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially, or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg–de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.},
author = {Rudy, Samuel H. and Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
doi = {10.1126/sciadv.1602614},
file = {:Users/john/Documents/Mendeley Desktop/Rudy et al/Science Advances/Rudy et al. - 2017 - Data-driven discovery of partial differential equations.pdf:pdf},
issn = {2375-2548},
journal = {Science Advances},
month = {apr},
number = {4},
pages = {e1602614},
publisher = {American Association for the Advancement of Science},
title = {{Data-driven discovery of partial differential equations}},
url = {http://advances.sciencemag.org/lookup/doi/10.1126/sciadv.1602614},
volume = {3},
year = {2017}
}
@article{Sivia1994,
abstract = {This paper presents a method for the reliable extraction of structure-factor amplitude information from the least-squares integrated-intensity refinement of powder diffraction data. The inevitable overlap of Bragg reflections can lead to strongly correlated reflection intensities that can, in turn, produce unrealistic negative intensity estimates. A Bayesian method is presented that tackles the problem of highly correlated positive and negative intensities. The results indicate that accurate structure-factor amplitudes may be recovered even in regions of a powder diffraction pattern where overlap is almost complete.},
author = {Sivia, D. S. and David, W. I.F.},
doi = {10.1107/S0108767394003235},
file = {:Users/john/Documents/Mendeley Desktop/Sivia, David/Acta Crystallographica Section A/Sivia, David - 1994 - A Bayesian approach to extracting structure‐factor amplitudes from powder diffraction data.pdf:pdf},
issn = {16005724},
journal = {Acta Crystallographica Section A},
number = {6},
pages = {703--714},
publisher = {International Union of Crystallography},
title = {{A Bayesian approach to extracting structure‐factor amplitudes from powder diffraction data}},
volume = {50},
year = {1994}
}
@article{Sivia1992a,
abstract = {We consider the analysis of quasielastic neutron scattering data from a Bayesian point-of-view. This enables us to use probability theory to assess how many quasielastic components there is most evidence for in the data, as well as providing an optimal estimate of their parameters. We review the theory briefly, describe an efficient algorithm for its implementation and illustrate its use with both simulated and real data. {\textcopyright} 1992.},
author = {Sivia, D. S. and Carlile, C. J. and Howells, W. S. and K{\"{o}}nig, S.},
doi = {10.1016/0921-4526(92)90036-R},
file = {:Users/john/Documents/Mendeley Desktop/Sivia et al/Physica B Physics of Condensed Matter/Sivia et al. - 1992 - Bayesian analysis of quasielastic neutron scattering data.pdf:pdf},
issn = {09214526},
journal = {Physica B: Physics of Condensed Matter},
number = {4},
pages = {341--348},
title = {{Bayesian analysis of quasielastic neutron scattering data}},
volume = {182},
year = {1992}
}
@article{Weideman2007,
author = {Weideman, J a C and Trefethen, L N},
file = {:Users/john/Documents/Mendeley Desktop/Weideman, Trefethen/Mathematics of Computation/Weideman, Trefethen - 2007 - Parabolic and Hyperbolic Contours for Computing the Bromwich Integral.pdf:pdf},
journal = {Mathematics of Computation},
keywords = {and phrases,fractional dif-,laplace transform,s method,talbot,trapezoidal rule},
number = {259},
pages = {1341--1356},
title = {{Parabolic and Hyperbolic Contours for Computing the Bromwich Integral}},
volume = {76},
year = {2007}
}
@article{Hogg2010,
abstract = {We go through the many considerations involved in fitting a model to data, using as an example the fit of a straight line to a set of points in a two-dimensional plane. Standard weighted least-squares fitting is only appropriate when there is a dimension along which the data points have negligible uncertainties, and another along which all the uncertainties can be described by Gaussians of known variance; these conditions are rarely met in practice. We consider cases of general, heterogeneous, and arbitrarily covariant two-dimensional uncertainties, and situations in which there are bad data (large outliers), unknown uncertainties, and unknown but expected intrinsic scatter in the linear relationship being fit. Above all we emphasize the importance of having a "generative model" for the data, even an approximate one. Once there is a generative model, the subsequent fitting is non-arbitrary because the model permits direct computation of the likelihood of the parameters or the posterior probability distribution. Construction of a posterior probability distribution is indispensible if there are "nuisance parameters" to marginalize away.},
archivePrefix = {arXiv},
arxivId = {1008.4686},
author = {Hogg, David W. and Bovy, Jo and Lang, Dustin},
doi = {arxiv.org/abs/1008.4686},
eprint = {1008.4686},
file = {:Users/john/Documents/Mendeley Desktop/Hogg, Bovy, Lang/Unknown/Hogg, Bovy, Lang - 2010 - Data analysis recipes Fitting a model to data.pdf:pdf},
isbn = {2050-084X},
issn = {2050-084X},
pmid = {25584625},
title = {{Data analysis recipes: Fitting a model to data}},
url = {http://arxiv.org/abs/1008.4686},
year = {2010}
}
@article{Raissi2018a,
abstract = {We introduce the concept of numerical Gaussian processes, which we define as Gaussian processes with covariance functions resulting from temporal discretization of time-dependent partial differential equations. Numerical Gaussian processes, by construction, are designed to deal with cases where (a) all we observe are noisy data on black-box initial conditions, and (b) we are interested in quantifying the uncertainty associated with such noisy data in our solutions to time-dependent partial differential equations. Our method circumvents the need for spatial discretization of the differential operators by proper placement of Gaussian process priors. This is an attempt to construct structured and data-efficient learning machines, which are explicitly informed by the underlying physics that possibly generated the observed data. The effectiveness of the proposed approach is demonstrated through several benchmark problems involving linear and nonlinear time-dependent operators. In all examples, we are able to r...},
author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
doi = {10.1137/17M1120762},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Perdikaris, Karniadakis/SIAM Journal on Scientific Computing/Raissi, Perdikaris, Karniadakis - 2018 - Numerical Gaussian Processes for Time-Dependent and Nonlinear Partial Differential Equations.pdf:pdf},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
keywords = {65C20,65M75,68T05,Bayesian modeling,Runge--Kutta methods,linear multistep methods,probabilistic machine learning,uncertainty quantification},
month = {jan},
number = {1},
pages = {A172--A198},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Numerical Gaussian Processes for Time-Dependent and Nonlinear Partial Differential Equations}},
url = {https://epubs.siam.org/doi/10.1137/17M1120762},
volume = {40},
year = {2018}
}
@article{Raissi2018,
abstract = {While there is currently a lot of enthusiasm about “big data” useful data is usually “small” and expensive to acquire. In this paper, we present a new paradigm of learning partial differential equations from small data. In particular, we introduce hidden physics models, which are essentially data-efficient learning machines capable of leveraging the underlying laws of physics, expressed by time dependent and nonlinear partial differential equations, to extract patterns from high-dimensional data generated from experiments. The proposed methodology may be applied to the problem of learning, system identification, or data-driven discovery of partial differential equations. Our framework relies on Gaussian processes, a powerful tool for probabilistic inference over functions, that enables us to strike a balance between model complexity and data fitting. The effectiveness of the proposed approach is demonstrated through a variety of canonical problems, spanning a number of scientific domains, including the Navier–Stokes, Schr{\"{o}}dinger, Kuramoto–Sivashinsky, and time dependent linear fractional equations. The methodology provides a promising new direction for harnessing the long-standing developments of classical methods in applied mathematics and mathematical physics to design learning machines with the ability to operate in complex domains without requiring large quantities of data.},
author = {Raissi, Maziar and Karniadakis, George Em},
doi = {10.1016/j.jcp.2017.11.039},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Karniadakis/Journal of Computational Physics/Raissi, Karniadakis - 2018 - Hidden physics models Machine learning of nonlinear partial differential equations.pdf:pdf},
issn = {10902716},
journal = {Journal of Computational Physics},
keywords = {Bayesian modeling,Fractional equations,Probabilistic machine learning,Small data,System identification,Uncertainty quantification},
pages = {125--141},
publisher = {Elsevier Inc.},
title = {{Hidden physics models: Machine learning of nonlinear partial differential equations}},
url = {https://doi.org/10.1016/j.jcp.2017.11.039},
volume = {357},
year = {2018}
}
@article{Raissi2019,
abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
doi = {10.1016/J.JCP.2018.10.045},
file = {:Users/john/Documents/Mendeley Desktop/Raissi, Perdikaris, Karniadakis/Journal of Computational Physics/Raissi, Perdikaris, Karniadakis - 2019 - Physics-informed neural networks A deep learning framework for solving forward and inverse prob.pdf:pdf},
issn = {0021-9991},
journal = {Journal of Computational Physics},
month = {feb},
pages = {686--707},
publisher = {Academic Press},
title = {{Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations}},
url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125{\#}!},
volume = {378},
year = {2019}
}
